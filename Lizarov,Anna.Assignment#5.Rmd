---
title: "Lizarov,Anna.Assignment#5"
author: "Anna Lizarov"
date: "November 13, 2018"
output: html_document
---

#Call Libraries
```{r}
library(rpart)
library(party)
```
## Part I

```{r}
(D1 <- read.csv("intelligent_tutor.csv", header=TRUE))
```

#Classification Tree
```{r}
c.tree <- rpart(action ~ hint.y + complete, method="class", data=D1) #Notice the standard R notion for a formula X ~ Y

#Look at the error of this tree
printcp(c.tree)
```
```{r}
#Plot the tree
post(c.tree, file = "tree.ps", title = "Session Completion Action: 1 - Ask teacher, 2 - Start new session, 3 - Give up")
```


## Part II

#Regression Tree
```{r}
hist(D1$score)
```

#Create a categorical outcome variable based on student score to advise the teacher using an "ifelse" statement
```{r}
D1$advice <- ifelse(D1$score <=0.4, "intervene", ifelse(D1$score > 0.4 & D1$score <=0.8, "monitor", "no action"))
```

#Build a decision tree that predicts "advice" based on how many problems students have answered before, the percentage of those problems they got correct and how many hints they required
```{r}
score_ctree <- ctree(factor(advice) ~ prior_prob_count + prior_percent_correct + hints, D1)
```

#Plot tree
```{r}
plot(score_ctree)
```

#Interpretation:
```{r}
#Answer: The first behavior that the teacher should pay close attention to the when the student is requesting at most 12 hints and answered less than 63% of problems correctly before the current session, and scored less than 81%. The second behavior is when a student asked for more than 12 hints and still scored less than 81%. In particular, for node 7, 60% of the students are classified into "monitor" group and 30% of the students are placed into "intervene" group. Likewise, for node 9, 60% of the students are classified into "monitor" group and 40% of the students are placed into "intervene" group. 
```

#Test Tree
```{r}
#Upload new data

D2 <- read.csv("intelligent_tutor_new.csv", header=TRUE)

#Generate predicted advice for new students based on tree generated from old students

D2$prediction <- predict(score_ctree, D2)

```

##Part III
Compare the predicted advice with the actual advice that these students recieved. What is the difference between the observed and predicted results?
```{r}
#If the model was perfect, would say "no action" for all students due to their score of 1. In other words, everyone scored higher than 80%. 

table(D2$prediction)

```
```{r}
(no_action <- 116/nrow(D2)) # The model is correct 58% of the time
```

```{r}
(monitor <- 84/nrow(D2)) # The error rate of the model is 42%. 
# Another way to calculate: 1- no_action
```

```{r}
# Answer: For the observed results, it is supposed to say "no action" for all students since this dataset represents those students that scored higher than 80%, which is indicated by their score of 1. The model predicted the advice correctly 58% of the time. However, the error rate of the model is 42% percent since 42% of the time, the predicted advice was "monitor". 
```

